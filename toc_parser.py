#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›®å½•è§£ææ¨¡å—
ä»index.htmlä¸­è§£æå¤šçº§ç›®å½•ç»“æ„ï¼Œæ”¯æŒåµŒå¥—çš„ç« èŠ‚å’Œå­ç« èŠ‚
"""

import os
import re
import sys
from typing import List, Dict, Any
from pathlib import Path
from bs4 import BeautifulSoup


class TOCParser:
    def __init__(self):
        pass
    
    def parse_toc(self, html_content: str) -> Dict[str, Any]:
        """
        è§£æHTMLå†…å®¹ï¼Œæå–å¤šçº§ç›®å½•ç»“æ„
        """
        # ä½¿ç”¨BeautifulSoupè§£æHTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æ‰¾åˆ°èœå•å®¹å™¨
        menu_container = soup.find('aside', class_='menu')
        if not menu_container:
            raise ValueError('æ— æ³•æ‰¾åˆ°èœå•å®¹å™¨')
        
        # æ‰¾åˆ°ä¸»è¦çš„ulåˆ—è¡¨
        main_ul = menu_container.find('ul', class_='menu-list')
        if not main_ul:
            main_ul = menu_container.find('ul')
        
        if not main_ul:
            raise ValueError('æ— æ³•æ‰¾åˆ°ç›®å½•åˆ—è¡¨')
        
        # è§£æå±‚çº§ç»“æ„
        hierarchical_toc = self._parse_hierarchical_structure(main_ul)
        
        # æ‰å¹³åŒ–ç»“æ„
        flat_toc = self._flatten_hierarchy(hierarchical_toc)
        
        return {
            'hierarchical': hierarchical_toc,
            'flat': flat_toc,
            'total_items': len(flat_toc)
        }
    
    def _parse_hierarchical_structure(self, main_ul) -> List[Dict[str, Any]]:
        """
        è§£æå±‚çº§ç»“æ„
        """
        items = []
        
        # è§£æä¸»åˆ—è¡¨ä¸­çš„lié¡¹
        for li in main_ul.find_all('li', recursive=False):
            # æŸ¥æ‰¾aæ ‡ç­¾
            a_tag = li.find('a', href=True)
            if a_tag and a_tag['href'].endswith('.html'):
                href = a_tag['href']
                
                # æŸ¥æ‰¾æ ‡é¢˜æ–‡æœ¬
                title_span = a_tag.find('span', class_='menu-list-title')
                if title_span:
                    title = title_span.get_text().strip()
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ul
                    children = []
                    sub_ul = li.find('ul')
                    if sub_ul:
                        children = self._parse_hierarchical_structure(sub_ul)
                    
                    item = {
                        'href': href,
                        'title': title,
                        'level': 1,
                        'children': children,
                        'is_folder': len(children) > 0
                    }
                    items.append(item)
        
        return items
    
    def _flatten_hierarchy(self, hierarchical: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†å±‚çº§ç»“æ„æ‰å¹³åŒ–ï¼Œç”Ÿæˆè¿ç»­çš„ç´¢å¼•
        """
        flat = []
        index_counter = 1
        
        def flatten_items(items, level=1):
            nonlocal index_counter
            
            for item in items:
                # ä¸ºå½“å‰é¡¹ç”Ÿæˆç´¢å¼•
                display_index = str(index_counter)
                flat_item = {
                    'href': item['href'],
                    'title': item['title'],
                    'level': item['level'],
                    'index': len(flat) + 1,
                    'display_index': display_index,
                    'has_children': len(item['children']) > 0
                }
                flat.append(flat_item)
                
                # å¤„ç†å­é¡¹ç›®
                if item['children']:
                    # ä¸ºæ¯ä¸ªå­é¡¹ç›®ç”Ÿæˆå¸¦å‰ç¼€çš„ç´¢å¼•
                    for i, child in enumerate(item['children']):
                        child_display_index = f"{display_index}.{i + 1}"
                        flat_child = {
                            'href': child['href'],
                            'title': child['title'],
                            'level': child['level'],
                            'index': len(flat) + 1,
                            'display_index': child_display_index,
                            'has_children': False
                        }
                        flat.append(flat_child)
                
                index_counter += 1
        
        flatten_items(hierarchical)
        return flat
    
    def validate_toc_files(self, flat_toc: List[Dict[str, Any]], src_dir: str) -> Dict[str, Any]:
        """
        éªŒè¯ç›®å½•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        """
        valid_files = []
        missing_files = []
        
        src_path = Path(src_dir)
        
        for item in flat_toc:
            file_path = src_path / item['href']
            if file_path.exists():
                valid_files.append(item)
            else:
                missing_files.append({
                    **item,
                    'file_path': str(file_path)
                })
        
        return {
            'valid_files': valid_files,
            'missing_files': missing_files,
            'total_valid': len(valid_files),
            'total_missing': len(missing_files)
        }
    
    def generate_bookmark_text(self, flat_toc: List[Dict[str, Any]], doc_title: str, total_pages: int = 0) -> str:
        """
        ç”Ÿæˆä¹¦ç­¾æ–‡æœ¬ï¼ˆæŒ‰ç…§æ¨¡æ¿æ ¼å¼ï¼‰
        """
        bookmark_lines = []
        
        for item in flat_toc:
            # æ ¹æ®å±‚çº§æ·»åŠ ç¼©è¿›ï¼ˆæ¨¡æ¿ä½¿ç”¨4ä¸ªç©ºæ ¼çš„ç¼©è¿›ï¼‰
            if item['level'] == 1:
                indent = ''
            else:
                indent = '    ' * (item['level'] - 1)
            
            # æ„å»ºä¹¦ç­¾æ¡ç›®ï¼Œæ ¼å¼ï¼šåºå·.æ ‡é¢˜(ç¬¬Xé¡µ)
            # æ³¨æ„ï¼šè¿™é‡Œé¡µç æ˜¯é¢„ä¼°çš„ï¼Œå®é™…é¡µç éœ€è¦åœ¨PDFç”Ÿæˆåç¡®å®š
            estimated_page = 3 + item['index'] - 1  # ä»ç¬¬3é¡µå¼€å§‹ï¼ˆå°é¢+ç›®å½•ï¼‰
            bookmark_line = f"{indent}{item['display_index']}.{item['title']}(ç¬¬{estimated_page}é¡µ)"
            bookmark_lines.append(bookmark_line)
        
        return f"{doc_title}ç›®å½•ï¼š\n\n{chr(10).join(bookmark_lines)}\n\næ€»é¡µæ•°ï¼š{total_pages}"
    
    def generate_pdf_bookmarks(self, flat_toc: List[Dict[str, Any]], start_page: int = 3) -> List[Dict[str, Any]]:
        """
        ç”ŸæˆPDFä¹¦ç­¾æ•°æ®
        """
        bookmarks = []
        
        for item in flat_toc:
            bookmark = {
                'title': item['title'],
                'level': item['level'],
                'page_index': start_page + item['index'] - 1,
                'display_index': item['display_index']
            }
            bookmarks.append(bookmark)
        
        return bookmarks
    
    def generate_bookmarks_file(self, flat_toc: List[Dict[str, Any]], doc_title: str, output_file: str = 'output/bookmarks.txt', page_map: Dict[str, int] = None) -> str:
        """
        ç”Ÿæˆç¬¦åˆæ¨¡æ¿æ ¼å¼çš„bookmarks.txtæ–‡ä»¶
        """
        bookmark_lines = []
        
        for item in flat_toc:
            # æ ¹æ®display_indexçš„å±‚çº§æ·»åŠ ç¼©è¿›ï¼ˆæ¨¡æ¿ä½¿ç”¨4ä¸ªç©ºæ ¼çš„ç¼©è¿›ï¼‰
            if '.' in item['display_index']:
                # å­ç« èŠ‚ï¼Œæ ¹æ®ç‚¹çš„æ•°é‡ç¡®å®šç¼©è¿›
                level = item['display_index'].count('.')
                indent = '    ' * level
            else:
                # ä¸»ç« èŠ‚ï¼Œæ— ç¼©è¿›
                indent = ''
            
            # ä½¿ç”¨å®é™…é¡µç æˆ–é¢„ä¼°é¡µç 
            actual_page = None
            if page_map and item['title'] in page_map:
                # PDFé¡µç ä»0å¼€å§‹ï¼Œä½†ä¹¦ç­¾æ˜¾ç¤ºä»1å¼€å§‹
                actual_page = page_map[item['title']] + 1
            else:
                # æ„å»ºä¹¦ç­¾æ¡ç›®ï¼Œä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿æ ¼å¼
                # ä¸»ç« èŠ‚ï¼šåºå·.æ ‡é¢˜(ç¬¬Xé¡µ)  å­ç« èŠ‚ï¼šåºå· æ ‡é¢˜(ç¬¬Xé¡µ)
                # æ³¨æ„ï¼šè¿™é‡Œé¡µç æ˜¯é¢„ä¼°çš„ï¼Œå®é™…é¡µç éœ€è¦åœ¨PDFç”Ÿæˆåç¡®å®š
                actual_page = 2 + item['index']  # ä»ç¬¬3é¡µå¼€å§‹ï¼ˆå°é¢+ç›®å½•ï¼‰
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºä¸»ç« èŠ‚ï¼ˆä¸åŒ…å«ç‚¹çš„åºå·ï¼‰
            if '.' not in item['display_index']:
                # ä¸»ç« èŠ‚ï¼Œåºå·å’Œæ ‡é¢˜ä¹‹é—´ç”¨ç‚¹
                bookmark_line = f"{indent}{item['display_index']}.{item['title']}(ç¬¬{actual_page}é¡µ)"
            else:
                # å­ç« èŠ‚ï¼Œåºå·å’Œæ ‡é¢˜ä¹‹é—´ç”¨ç©ºæ ¼
                bookmark_line = f"{indent}{item['display_index']} {item['title']}(ç¬¬{actual_page}é¡µ)"
            bookmark_lines.append(bookmark_line)
        
        # ç”Ÿæˆå®Œæ•´çš„ä¹¦ç­¾æ–‡æœ¬ï¼Œä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿æ ¼å¼ï¼šåªæœ‰ä¹¦ç­¾æ¡ç›®ï¼Œæ²¡æœ‰æ ‡é¢˜å’Œæ€»é¡µæ•°
        bookmark_text = chr(10).join(bookmark_lines)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir:  # åªæœ‰å½“ç›®å½•ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
            os.makedirs(output_dir, exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(bookmark_text)
        
        return output_file
    
    def extract_document_title(self, html_file_path: str) -> str:
        """
        ä»HTMLæ–‡ä»¶ä¸­æå–æ–‡æ¡£æ ‡é¢˜
        """
        try:
            with open(html_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°è¯•ä»<title>æ ‡ç­¾æå–
            title_match = re.search(r'<title[^>]*>(.*?)</title>', content, re.IGNORECASE)
            if title_match:
                title = title_match.group(1).strip()
                # æ¸…ç†æ ‡é¢˜ä¸­çš„å¤šä½™å†…å®¹
                title = re.sub(r'\s*-\s*.*$', '', title)  # ç§»é™¤" - ä½œè€…å"ç­‰åç¼€
                title = re.sub(r'\s*\|\s*.*$', '', title)  # ç§»é™¤" | ç½‘ç«™å"ç­‰åç¼€
                if title:
                    return title
            
            # å°è¯•ä»<h1>æ ‡ç­¾æå–
            h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', content, re.IGNORECASE)
            if h1_match:
                return h1_match.group(1).strip()
            
            # å°è¯•ä»<meta>æ ‡ç­¾æå–
            meta_title_match = re.search(r'<meta[^>]*name=["\']title["\'][^>]*content=["\']([^"\']*)["\']',
                                          content, re.IGNORECASE)
            if meta_title_match:
                return meta_title_match.group(1).strip()
            
            # è¿”å›é»˜è®¤æ ‡é¢˜
            return "æ–‡æ¡£"
            
        except Exception as e:
            print(f"[WARNING] æå–æ–‡æ¡£æ ‡é¢˜å¤±è´¥: {e}")
            return "æ–‡æ¡£"
    
    def parse_from_file(self, file_path: str) -> Dict[str, Any]:
        """
        ä»æ–‡ä»¶è§£æç›®å½•
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        return self.parse_toc(html_content)
    
    def scan_directory_structure(self, src_dir: str) -> Dict[str, Any]:
        """
        æ‰«æsrcæ–‡ä»¶å¤¹çš„å®é™…æ–‡ä»¶ç»“æ„
        è¿”å›ç›®å½•ç»“æ„å’Œæ–‡ä»¶åˆ—è¡¨
        """
        src_path = Path(src_dir)
        if not src_path.exists():
            raise FileNotFoundError(f"srcç›®å½•ä¸å­˜åœ¨: {src_dir}")
        
        structure = []
        files = []
        
        # æ‰«ææ ¹ç›®å½•çš„HTMLæ–‡ä»¶
        root_html_files = [f for f in src_path.glob('*.html') if f.name != 'index.html']
        
        for html_file in root_html_files:
            relative_path = html_file.relative_to(src_path)
            files.append({
                'path': str(relative_path),
                'name': html_file.name,
                'size': html_file.stat().st_size,
                'type': 'file',
                'level': 0
            })
        
        # æ‰«æå­ç›®å½•ï¼Œä½†å¿½ç•¥assetsæ–‡ä»¶å¤¹
        subdirs = [d for d in src_path.iterdir() if d.is_dir() and not d.name.startswith('.') and d.name != 'assets']
        
        for subdir in sorted(subdirs):
            dir_info = {
                'name': subdir.name,
                'path': str(subdir.relative_to(src_path)),
                'type': 'directory',
                'level': 0,
                'files': [],
                'subdirs': []
            }
            
            # æ‰«æå­ç›®å½•ä¸­çš„æ–‡ä»¶
            dir_files = [f for f in subdir.glob('*.html') if f.name != 'index.html']
            for file in sorted(dir_files):
                relative_path = file.relative_to(src_path)
                file_info = {
                    'path': str(relative_path),
                    'name': file.name,
                    'size': file.stat().st_size,
                    'type': 'file',
                    'level': 1
                }
                files.append(file_info)
                dir_info['files'].append(file_info)
            
            # æ‰«æå­ç›®å½•çš„å­ç›®å½•
            sub_subdirs = [d for d in subdir.iterdir() if d.is_dir() and not d.name.startswith('.')]
            for sub_subdir in sorted(sub_subdirs):
                sub_subdir_info = {
                    'name': sub_subdir.name,
                    'path': str(sub_subdir.relative_to(src_path)),
                    'type': 'directory',
                    'level': 1,
                    'files': []
                }
                
                # æ‰«æå­å­ç›®å½•ä¸­çš„æ–‡ä»¶
                sub_subdir_files = [f for f in sub_subdir.glob('*.html') if f.name != 'index.html']
                for file in sorted(sub_subdir_files):
                    relative_path = file.relative_to(src_path)
                    file_info = {
                        'path': str(relative_path),
                        'name': file.name,
                        'size': file.stat().st_size,
                        'type': 'file',
                        'level': 2
                    }
                    files.append(file_info)
                    sub_subdir_info['files'].append(file_info)
                
                dir_info['subdirs'].append(sub_subdir_info)
            
            structure.append(dir_info)
        
        return {
            'structure': structure,
            'files': files,
            'total_files': len(files),
            'total_dirs': len(structure) + sum(len(d['subdirs']) for d in structure)
        }
    
    def generate_file_structure_text(self, structure_data: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ–‡ä»¶ç»“æ„æ–‡æœ¬
        """
        lines = []
        lines.append("src/ æ–‡ä»¶å¤¹ç»“æ„:")
        lines.append("=" * 50)
        lines.append("")
        
        # æ·»åŠ æ ¹ç›®å½•æ–‡ä»¶
        root_files = [f for f in structure_data['files'] if f['level'] == 0]
        if root_files:
            lines.append("æ ¹ç›®å½•æ–‡ä»¶:")
            for file in sorted(root_files, key=lambda x: x['name']):
                lines.append(f"  ğŸ“„ {file['name']}")
            lines.append("")
        
        # æ·»åŠ ç›®å½•ç»“æ„
        for dir_info in sorted(structure_data['structure'], key=lambda x: x['name']):
            lines.append(f"ğŸ“ {dir_info['name']}/")
            
            # æ·»åŠ ç›®å½•ä¸­çš„æ–‡ä»¶
            for file in sorted(dir_info['files'], key=lambda x: x['name']):
                lines.append(f"    ğŸ“„ {file['name']}")
            
            # æ·»åŠ å­ç›®å½•
            for sub_dir in sorted(dir_info['subdirs'], key=lambda x: x['name']):
                lines.append(f"    ğŸ“ {sub_dir['name']}/")
                for file in sorted(sub_dir['files'], key=lambda x: x['name']):
                    lines.append(f"        ğŸ“„ {file['name']}")
            
            lines.append("")
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        lines.append("=" * 50)
        lines.append(f"æ€»è®¡: {structure_data['total_files']} ä¸ªæ–‡ä»¶, {structure_data['total_dirs']} ä¸ªç›®å½•")
        
        return '\n'.join(lines)
    
    def generate_file_structure_file(self, src_dir: str, output_file: str = 'output/file_structure.txt') -> str:
        """
        ç”Ÿæˆfile_structure.txtæ–‡ä»¶
        """
        # æ‰«æç›®å½•ç»“æ„
        structure_data = self.scan_directory_structure(src_dir)
        
        # ç”Ÿæˆæ–‡ä»¶ç»“æ„æ–‡æœ¬
        structure_text = self.generate_file_structure_text(structure_data)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(structure_text)
        
        return output_file
    
    def validate_directory_structure(self, hierarchical_toc: List[Dict[str, Any]], src_dir: str, level: int = 1) -> Dict[str, Any]:
        """
        éªŒè¯ç›®å½•ç»“æ„ä¸å®é™…æ–‡ä»¶ç»“æ„æ˜¯å¦åŒ¹é…
        è¿”å›éªŒè¯ç»“æœï¼ŒåŒ…æ‹¬è­¦å‘Šå’Œé”™è¯¯ä¿¡æ¯
        """
        warnings = []
        errors = []
        
        src_path = Path(src_dir)
        
        for item in hierarchical_toc:
            href = item['href']
            file_path = src_path / href
            
            # æ£€æŸ¥ä¸»ç« èŠ‚å¯¹åº”çš„ç›®å½•ç»“æ„
            if level == 1:
                base_name = Path(href).stem
                expected_dir = src_path / base_name
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„å­ç›®å½•
                if expected_dir.exists():
                    # æ£€æŸ¥HTMLä¸­çš„å­ç« èŠ‚æ•°é‡ä¸ç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡æ˜¯å¦åŒ¹é…
                    html_children = item.get('children', [])
                    
                    # è·å–ç›®å½•ä¸­çš„HTMLæ–‡ä»¶
                    if expected_dir.is_dir():
                        dir_html_files = list(expected_dir.glob('*.html'))
                        dir_html_files = [f for f in dir_html_files if f.name != 'index.html']
                        
                        if len(html_children) != len(dir_html_files):
                            warning_msg = f"ä¸»ç« èŠ‚ '{item['title']}' çš„HTMLå­ç« èŠ‚æ•°é‡({len(html_children)})ä¸ç›®å½•ä¸­æ–‡ä»¶æ•°é‡({len(dir_html_files)})ä¸åŒ¹é…"
                            warnings.append({
                                'type': 'mismatch_count',
                                'chapter': item['title'],
                                'html_count': len(html_children),
                                'dir_count': len(dir_html_files),
                                'message': warning_msg
                            })
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰HTMLä¸­æœªåŒ…å«çš„æ–‡ä»¶
                        dir_file_names = set(f.name for f in dir_html_files)
                        html_file_names = set(child['href'] for child in html_children)
                        missing_in_html = dir_file_names - html_file_names
                        
                        if missing_in_html:
                            warning_msg = f"ç›®å½• '{base_name}/' ä¸­å­˜åœ¨HTMLæœªåŒ…å«çš„æ–‡ä»¶: {', '.join(missing_in_html)}"
                            warnings.append({
                                'type': 'missing_in_html',
                                'chapter': item['title'],
                                'missing_files': list(missing_in_html),
                                'message': warning_msg
                            })
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å­ç›®å½•ä½†æ²¡æœ‰åœ¨HTMLä¸­å®šä¹‰å­ç« èŠ‚
                elif len(item.get('children', [])) > 0:
                    # HTMLä¸­æœ‰å­ç« èŠ‚ï¼Œä½†å¯¹åº”çš„ç›®å½•ä¸å­˜åœ¨
                    pass  # è¿™ä¸æ˜¯é”™è¯¯ï¼Œå› ä¸ºå­ç« èŠ‚å¯èƒ½æ˜¯å•ç‹¬çš„HTMLæ–‡ä»¶
            
            # é€’å½’æ£€æŸ¥å­ç« èŠ‚
            if item.get('children', []):
                child_result = self.validate_directory_structure(item['children'], src_dir, level + 1)
                warnings.extend(child_result['warnings'])
                errors.extend(child_result['errors'])
        
        return {
            'warnings': warnings,
            'errors': errors,
            'total_warnings': len(warnings),
            'total_errors': len(errors)
        }


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æç›®å½•ç»“æ„å¹¶ç”Ÿæˆä¹¦ç­¾æ–‡ä»¶
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='ç›®å½•è§£æå™¨')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œç”Ÿæˆtest_bookmarks.txt')
    parser.add_argument('--page-map', type=str, help='é¡µç æ˜ å°„JSONå­—ç¬¦ä¸²')
    
    args = parser.parse_args()
    
    # è§£æé¡µç æ˜ å°„
    page_map = None
    if args.page_map:
        try:
            import json
            page_map = json.loads(args.page_map)
        except Exception as e:
            print(f'[WARNING] é¡µç æ˜ å°„è§£æå¤±è´¥: {e}')
    
    toc_parser = TOCParser()
    
    try:
        # è§£æå½“å‰é¡¹ç›®çš„index.html
        index_html_path = os.path.join(os.getcwd(), 'src', 'index.html')
        
        # è®¾ç½®UTF-8è¾“å‡ºç¼–ç ä»¥è§£å†³Windowså‘½ä»¤è¡Œä¹±ç é—®é¢˜
        import sys
        if sys.platform == 'win32':
            sys.stdout.reconfigure(encoding='utf-8')
        
        print('[INFO] æ­£åœ¨è§£æç›®å½•ç»“æ„...')
        result = toc_parser.parse_from_file(index_html_path)
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
        print('[INFO] éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§...')
        validation = toc_parser.validate_toc_files(result['flat'], os.path.join(os.getcwd(), 'src'))
        
        # éªŒè¯ç›®å½•ç»“æ„
        print('[INFO] éªŒè¯ç›®å½•ç»“æ„...')
        structure_validation = toc_parser.validate_directory_structure(result['hierarchical'], os.path.join(os.getcwd(), 'src'))
        
        # è¾“å‡ºè§£æç»“æœæ‘˜è¦
        print('[INFO] è§£æç»“æœ:')
        print(f'   æ€»æ¡ç›®æ•°: {result["total_items"]}')
        print(f'   å±‚çº§æ·±åº¦: {max(item["level"] for item in result["flat"])}')
        print(f'   æœ‰æ•ˆæ–‡ä»¶: {validation["total_valid"]}')
        print(f'   ç¼ºå¤±æ–‡ä»¶: {validation["total_missing"]}')
        print(f'   ç»“æ„è­¦å‘Š: {structure_validation["total_warnings"]}')
        print(f'   ç»“æ„é”™è¯¯: {structure_validation["total_errors"]}')
        
        # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if structure_validation['warnings']:
            print('\n[WARN] ç»“æ„éªŒè¯è­¦å‘Š:')
            for warning in structure_validation['warnings']:
                print(f'   {warning["message"]}')
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if structure_validation['errors']:
            print('\n[ERROR] ç»“æ„éªŒè¯é”™è¯¯:')
            for error in structure_validation['errors']:
                print(f'   {error["message"]}')
        
        # æ˜¾ç¤ºç¼ºå¤±æ–‡ä»¶
        if validation['missing_files']:
            print('\n[ERROR] ç¼ºå¤±æ–‡ä»¶:')
            for file in validation['missing_files']:
                print(f'   {file["display_index"]}. {file["title"]} -> {file["file_path"]}')
        
        # ç”Ÿæˆæ–‡ä»¶ç»“æ„æ–‡ä»¶
        print('\n[INFO] ç”Ÿæˆæ–‡ä»¶ç»“æ„æ–‡ä»¶...')
        try:
            structure_file = toc_parser.generate_file_structure_file(os.path.join(os.getcwd(), 'src'))
            print(f'[INFO] æ–‡ä»¶ç»“æ„æ–‡ä»¶å·²ç”Ÿæˆ: {structure_file}')
        except Exception as e:
            print(f'[WARNING] ç”Ÿæˆæ–‡ä»¶ç»“æ„æ–‡ä»¶å¤±è´¥: {e}')
        
        # å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œç”Ÿæˆä¹¦ç­¾æ–‡ä»¶
        if structure_validation['total_errors'] == 0 and validation['total_missing'] == 0:
            print('\n[INFO] ç”Ÿæˆä¹¦ç­¾æ–‡ä»¶...')
            # ä»HTMLä¸­æå–æ–‡æ¡£æ ‡é¢˜
            doc_title = toc_parser.extract_document_title(index_html_path)
            
            # æ ¹æ®æ¨¡å¼ç”Ÿæˆä¸åŒçš„æ–‡ä»¶å
            if args.test:
                bookmarks_file = 'output/test_bookmarks.txt'
                # åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œåªä½¿ç”¨ç¬¬ä¸€ä¸ªç« èŠ‚åŠå…¶å­ç« èŠ‚
                if result['flat']:
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸»ç« èŠ‚
                    first_chapter = None
                    for item in result['flat']:
                        if '.' not in item['display_index']:
                            first_chapter = item['display_index']
                            break
                    
                    # å¦‚æœæ‰¾åˆ°äº†ç¬¬ä¸€ä¸ªä¸»ç« èŠ‚ï¼Œåªä¿ç•™è¯¥ç« èŠ‚åŠå…¶ç›´æ¥å­ç« èŠ‚
                    if first_chapter:
                        filtered_toc = [item for item in result['flat'] 
                                      if (item['display_index'] == first_chapter or 
                                          item['display_index'].startswith(first_chapter + '.'))]
                        toc_parser.generate_bookmarks_file(filtered_toc, doc_title, bookmarks_file, page_map)
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸»ç« èŠ‚ï¼Œåªä¿ç•™å‰4ä¸ªé¡¹ç›®ï¼ˆç¬¬ä¸€ä¸ªç« èŠ‚+3ä¸ªå­ç« èŠ‚ï¼‰
                        toc_parser.generate_bookmarks_file(result['flat'][:4], doc_title, bookmarks_file, page_map)
            else:
                bookmarks_file = 'output/bookmarks.txt'
                toc_parser.generate_bookmarks_file(result['flat'], doc_title, bookmarks_file, page_map)
            
            print(f'[INFO] ä¹¦ç­¾æ–‡ä»¶å·²ç”Ÿæˆ: {bookmarks_file}')
        else:
            print('\n[ERROR] ç”±äºå­˜åœ¨é”™è¯¯ï¼Œè·³è¿‡ä¹¦ç­¾æ–‡ä»¶ç”Ÿæˆ')
        
        print('\n[SUCCESS] ç›®å½•è§£æå®Œæˆ')
        
    except Exception as e:
        print(f'[ERROR] è§£æå¤±è´¥: {e}')
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    # è®¾ç½®è¾“å‡ºç¼–ç ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
    if sys.platform == 'win32':
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    main()
 